	model	micro-precision	micro-recall	micro-f1	macro-precision	macro-recall	macro-f1	accuracy
0	../final/models/neg_base	0.022935779816513763	0.022935779816513763	0.022935779816513763	0.022574123989218327	0.022935779816513763	0.022750710302009893	0.022935779816513763
1	../final/models/neg_nli	0.5688073394495413	0.5688073394495413	0.5688073394495413	0.6017170586039566	0.5688073394495413	0.5308608058608059	0.5688073394495413
2	../final/models/pos_base	0.9954128440366973	0.9954128440366973	0.9954128440366973	0.9954545454545455	0.9954128440366973	0.9954127475117311	0.9954128440366973
3	../final/models/pos_nli	0.9954128440366973	0.9954128440366973	0.9954128440366973	0.9954545454545455	0.9954128440366973	0.9954127475117311	0.9954128440366973
4	../final/models/synth_neg_base	0.06422018348623854	0.06422018348623854	0.06422018348623854	0.06186003215706186	0.06422018348623854	0.0629582806573957	0.06422018348623854
5	../final/models/synth_neg_nli	0.7155963302752294	0.7155963302752294	0.7155963302752294	0.730828151752726	0.7155963302752294	0.7108258451005562	0.7155963302752294
6	../final/models/synth_pos_base	0.9678899082568807	0.9678899082568807	0.9678899082568807	0.9679292929292929	0.9678899082568808	0.9678892325821181	0.9678899082568807
7	../final/models/synth_pos_nli	0.9862385321100917	0.9862385321100917	0.9862385321100917	0.9862794612794612	0.9862385321100917	0.9862382425351934	0.9862385321100917
8	JeremiahZ/bert-base-uncased-mnli	0.8440366972477065	0.8440366972477065	0.8440366972477065	0.8498074454428755	0.8440366972477065	0.8433908045977012	0.8440366972477065
